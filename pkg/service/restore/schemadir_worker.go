// Copyright (C) 2024 ScyllaDB

package restore

import (
	"bytes"
	"context"
	"path"

	"github.com/pkg/errors"
	"github.com/scylladb/go-set/strset"
	. "github.com/scylladb/scylla-manager/v3/pkg/service/backup/backupspec"
	"golang.org/x/sync/errgroup"
)

type schemaDirWorker struct {
	*schemaWorker

	fm             FilesMeta
	srcDir         string
	dstDir         string
	versionedFiles VersionedMap
	idM            map[string]string
	uuidM          map[string]string
}

type crossJob struct {
	content []byte
	file    string
}

// Generates jobs for SM routines while respecting maxInMemFileSize limit.
// SM jobs are sent over smCh and hosts send already processed files over generatorCh.
func (w *schemaDirWorker) crossGeneratorRoutine(ctx context.Context, crossHostCnt int, generatorCh, smCh chan string) func() error {
	const maxInMemFileSize = 1024 * 1024 // 1MB

	var (
		totalFiles = make(map[string]int) // Counts amount of hosts that are still processing file
		totalSize  int64                  // Total size of currently processed files
	)
	// Tries to generate as much SM jobs as possible.
	// Returns true when all jobs have been generated.
	fill := func() bool {
		done := true

		for _, f := range w.fm.Files {
			if _, ok := totalFiles[f]; !ok {
				size := w.versionedFiles[f].Size
				if totalSize == 0 || totalSize+size < maxInMemFileSize {
					select {
					case smCh <- f:
						totalFiles[f] = crossHostCnt
						totalSize += size
					default:
						done = false
					}
				} else {
					done = false
				}
			}
		}

		return done
	}

	return func() error {
		defer close(smCh)

		if fill() {
			return nil
		}

		for {
			select {
			case <-ctx.Done():
				return ctx.Err()
			case f, ok := <-generatorCh:
				if !ok {
					return nil
				}

				totalFiles[f]--
				if totalFiles[f] == 0 {
					totalSize -= w.versionedFiles[f].Size
					if fill() {
						return nil
					}
				}
			}
		}
	}
}

// Consumes jobs created by generator and creates jobs for cross hosts routines.
func (w *schemaDirWorker) crossManagerRoutine(ctx context.Context, localHost string, smCh chan string, crossCh []chan crossJob) func() error {
	return func() error {
		for {
			select {
			case <-ctx.Done():
				return ctx.Err()
			case f, ok := <-smCh:
				if !ok {
					return nil
				}

				srcFile := w.versionedFiles[f].FullName()
				srcPath := path.Join(w.srcDir, srcFile)
				content, err := w.client.RcloneCat(ctx, localHost, srcPath)
				if err != nil {
					return err
				}

				cj := crossJob{
					content: content,
					file:    f,
				}
				for _, ch := range crossCh {
					ch <- cj
				}
			}
		}
	}
}

// Consumes jobs generated by manager and acknowledges generator about processed files.
func (w *schemaDirWorker) crossHostRoutine(ctx context.Context, host string, renaming map[string]string, crossCh chan crossJob, genCh chan string) func() error {
	return func() error {
		for {
			select {
			case <-ctx.Done():
				return ctx.Err()
			case cj, ok := <-crossCh:
				if !ok {
					return nil
				}

				dstFile := renaming[cj.file]
				dstPath := path.Join(w.dstDir, dstFile)
				if err := w.client.RclonePut(ctx, host, dstPath, bytes.NewReader(cj.content)); err != nil {
					return err
				}
				genCh <- cj.file
			}
		}
	}
}

// Downloads SSTables from remote location to nodes from other regions.
func (w *schemaDirWorker) crossLocationSSTableDownload(ctx context.Context) error {
	const (
		smParallelism   = 10
		hostParallelism = 10
		chSize          = 10000
	)

	status, err := w.client.Status(ctx)
	if err != nil {
		return errors.Wrap(err, "get status")
	}

	localHosts := w.target.locationHosts[w.miwc.Location]
	crossS := strset.New(status.Hosts()...)
	crossS.Remove(localHosts...)
	crossHosts := crossS.List()

	crossSSTableUUIDFormat := make([]bool, len(crossHosts))
	for i, h := range crossHosts {
		ni, err := w.client.NodeInfo(ctx, h)
		if err != nil {
			return errors.Wrapf(err, "get node info on host %s", h)
		}
		crossSSTableUUIDFormat[i] = ni.SstableUUIDFormat
	}

	genCh := make(chan string, chSize)
	smCh := make(chan string, chSize)
	crossCh := make([]chan crossJob, len(crossHosts))
	for i := range crossCh {
		crossCh[i] = make(chan crossJob, chSize)
	}

	wg, wgCtx := errgroup.WithContext(ctx)
	wg.Go(w.crossGeneratorRoutine(wgCtx, len(crossHosts), genCh, smCh))
	wg.Go(func() error {
		// SM routines are handled as a separate sub-waitgroup, because
		// we need to close cross channels when they are no longer needed.
		smWG, smCtx := errgroup.WithContext(wgCtx)
		for i := 0; i < smParallelism; i++ {
			// Try to distribute local hosts equally
			smWG.Go(w.crossManagerRoutine(smCtx, localHosts[i%len(localHosts)], smCh, crossCh))
		}
		err := smWG.Wait()
		for _, ch := range crossCh {
			close(ch)
		}
		return err
	})
	for i := range crossHosts {
		h := crossHosts[i]
		ch := crossCh[i]
		renaming := w.idM
		if crossSSTableUUIDFormat[i] {
			renaming = w.uuidM
		}
		for j := 0; j < hostParallelism; j++ {
			wg.Go(w.crossHostRoutine(wgCtx, h, renaming, ch, genCh))
		}
	}

	return wg.Wait()
}
